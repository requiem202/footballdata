{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from football_loader import metrics\n",
    "\n",
    "\n",
    "def load_league_csv(league, start_year=2005):\n",
    "    df = None\n",
    "    files = os.listdir(f'fulldata/{league}')\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        year = int(file.strip('.csv'))\n",
    "        if year < start_year:\n",
    "            continue\n",
    "        df_year = pd.read_csv(f'fulldata/{league}/' + file,\n",
    "                              engine='python',\n",
    "                              # skiprows=1,\n",
    "                              # index_col=None,\n",
    "                              # names=['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A']\n",
    "                              )\n",
    "        df_year.reset_index(drop=True, inplace=True)\n",
    "        df_year['Year'] = year\n",
    "        df_year['Match'] = df_year.index + 1\n",
    "\n",
    "        if df is None:\n",
    "            df = df_year\n",
    "        else:\n",
    "            df = df.append(df_year, ignore_index=True, sort=False)\n",
    "\n",
    "    # print(len(df))\n",
    "    # print(df.shape)\n",
    "\n",
    "    # remove unused columns\n",
    "    # df_league = None\n",
    "    df.reset_index(inplace=True)\n",
    "    # df = df[['Year', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR',\n",
    "    #          \"B365H\", \"B365D\", \"B365A\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_features(df, teams):\n",
    "    # df_league = None\n",
    "    ret = {}\n",
    "\n",
    "    # if teams is None:\n",
    "    #     teams = np.unique(df.loc[df['Year'] == predict_year, 'HomeTeam'].values)\n",
    "    #     teams.sort()\n",
    "    for team in teams:\n",
    "\n",
    "        df_team = df[(df['HomeTeam'] == team) | (df['AwayTeam'] == team)]\n",
    "        all = pd.DataFrame(\n",
    "            data={\n",
    "                'Year': df_team['Year'],\n",
    "                'Date': df_team['Date'],\n",
    "                'Team': team,\n",
    "                'HomeMatch': df_team['HomeTeam'] == team\n",
    "            }\n",
    "        )\n",
    "        all['Opponent'] = np.where(all['HomeMatch'], df_team['AwayTeam'], df_team['HomeTeam'])\n",
    "        # X['HalfTimeGoals'] = np.where(X['HomeMatch'], df_team['HTHG'], df_team['HTAG'])\n",
    "        # X['HalfTimeOpponentGoals'] = np.where(X['HomeMatch'], df_team['HTAG'], df_team['HTHG'])\n",
    "        # X['HalfTimeLead'] = X['HalfTimeGoals'] > X['HalfTimeOpponentGoals']\n",
    "        # X['HalfTimeLeadMoreThanTwo'] = (X['HalfTimeGoals'] - X['HalfTimeOpponentGoals']) > 2\n",
    "        # X['FullTimeGoals'] = np.where(X['HomeMatch'], ath_madrid['FTHG'], ath_madrid['FTAG'])\n",
    "        # X['FullTimeOpponentGoals'] = np.where(X['HomeMatch'], ath_madrid['FTAG'], ath_madrid['FTHG'])\n",
    "        all['FTR'] = df_team['FTR']\n",
    "        # all['Won'] = np.where(all['HomeMatch'], df_team['FTR'] == 'H', df_team['FTR'] == 'A')\n",
    "        all['Won'] = np.where(df_team['FTR'] == '', False, np.where(all['HomeMatch'], df_team['FTR'] == 'H', df_team['FTR'] == 'A'))\n",
    "        all['Draw'] = np.where(df_team['FTR'] == '', False, df_team['FTR'] == 'D')\n",
    "        all['Lost'] = np.where(df_team['FTR'] == '', False, np.where(all['HomeMatch'], df_team['FTR'] == 'A', df_team['FTR'] == 'H'))\n",
    "        all['Result'] = np.where(df_team['FTR'] == '', '', np.where(all['Won'], 'Win', (np.where(all['Lost'], 'Lose', 'Draw'))))\n",
    "        # X['SumGoals'] = X.groupby('Opponent')['FullTimeGoals'].transform(sum)\n",
    "        all['B365Max'] = np.maximum(np.maximum(df_team['B365H'], df_team['B365A']), df_team['B365D'])\n",
    "        all['B365Min'] = np.minimum(np.minimum(df_team['B365H'], df_team['B365A']), df_team['B365D'])\n",
    "        all['B365Say'] = np.where(all['HomeMatch'],\n",
    "                                  # home match\n",
    "                                  np.where(all['B365Max'] == df_team['B365H'], -1,\n",
    "                                           np.where(all['B365Max'] == df_team['B365A'], 1,\n",
    "                                                    0)),\n",
    "                                  # away match\n",
    "                                  np.where(all['B365Max'] == df_team['B365H'], 1,\n",
    "                                           np.where(all['B365Max'] == df_team['B365A'], -1,\n",
    "                                                    0))\n",
    "                                  )\n",
    "        # all['B365Diff'] = np.where(all['B365Say'] == 1, all['B365Max'] - all['B365Min'],\n",
    "        #                            all['B365Min'] - all['B365Max'])\n",
    "        all['B365Diff'] = np.where(all['B365Say'] == 1, all['B365Min'] - all['B365Max'],\n",
    "                                   np.where(all['B365Say'] == -1, all['B365Max'] - all['B365Min'],\n",
    "                                            # draw\n",
    "                                            np.where(all['HomeMatch'],\n",
    "                                            df_team['B365A'] - df_team['B365H'],\n",
    "                                            df_team['B365H'] - df_team['B365A']\n",
    "                                            ))) * -1\n",
    "        all['Corners'] = np.where(all['HomeMatch'], df_team['HC'], df_team['AC'])\n",
    "        all['Shots'] = np.where(all['HomeMatch'], df_team['HS'], df_team['AS'])\n",
    "        all['ShotsOnTarget'] = np.where(all['HomeMatch'], df_team['HST'], df_team['AST'])\n",
    "        all['Points'] = np.where(all['Won'], 3,\n",
    "                                 np.where(all['Draw'], 1, 0)\n",
    "                                  )\n",
    "        all['AdjustedPoints'] = np.where(all['HomeMatch'],\n",
    "                                  # home match\n",
    "                                         np.where(all['Won'], 1,\n",
    "                                                  np.where(all['Draw'], 0, -1)\n",
    "                                                  )\n",
    "                                         ,\n",
    "                                  # away match\n",
    "                                         np.where(all['Won'], 1.5,\n",
    "                                                  np.where(all['Draw'], 0.5, 0)\n",
    "                                                  )\n",
    "                                  )\n",
    "        all['Goals'] = np.where(all['HomeMatch'], df_team['FTHG'], df_team['FTAG'])\n",
    "        all['Conceded'] = np.where(all['HomeMatch'], df_team['FTAG'], df_team['FTHG'])\n",
    "\n",
    "        # find number of times won against this opponent in last 5 meetings\n",
    "        for key, groupByOpponent in all.groupby('Opponent'):\n",
    "            # keep index as new a column, will be restored and assigned back to X later\n",
    "            idx = groupByOpponent.index\n",
    "\n",
    "            # make match day an index because rolling need an index date\n",
    "            xx = groupByOpponent.set_index('Date')\n",
    "            xx['idx'] = idx\n",
    "            # shift to exclude self\n",
    "            xx['Last5AgainstThisOpponentWon'] = xx['Won'].rolling(6).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "            xx['Last5AgainstThisOpponentDraw'] = xx['Draw'].rolling(6).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "            # xx['Last5AgainstThisOpponentLost'] = xx['Lost'].rolling(6).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "\n",
    "            xx['Last3AgainstThisOpponentWon'] = xx['Won'].rolling(4).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "            xx['Last3AgainstThisOpponentDraw'] = xx['Draw'].rolling(4).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "\n",
    "            xx['LastAgainstThisOpponentWon'] = xx['Won'].rolling(2).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "            xx['LastAgainstThisOpponentDraw'] = xx['Draw'].rolling(2).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "            # xx['LastThisOpponentLost'] = xx['Lost'].rolling(2).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "\n",
    "            # restore index\n",
    "            xx = xx.set_index('idx')\n",
    "\n",
    "            # assign back to the big dataframe\n",
    "            all.loc[xx.index, 'Last5AgainstThisOpponentWon'] = xx['Last5AgainstThisOpponentWon']\n",
    "            all.loc[xx.index, 'Last5AgainstThisOpponentDraw'] = xx['Last5AgainstThisOpponentDraw']\n",
    "            # X.loc[xx.index, 'Last5AgainstThisOpponentLost'] = xx['Last5AgainstThisOpponentLost']\n",
    "            all.loc[xx.index, 'Last3AgainstThisOpponentWon'] = xx['Last3AgainstThisOpponentWon']\n",
    "            all.loc[xx.index, 'Last3AgainstThisOpponentDraw'] = xx['Last3AgainstThisOpponentDraw']\n",
    "            all.loc[xx.index, 'LastAgainstThisOpponentWon'] = xx['LastAgainstThisOpponentWon']\n",
    "            all.loc[xx.index, 'LastAgainstThisOpponentDraw'] = xx['LastAgainstThisOpponentDraw']\n",
    "            # X.loc[xx.index, 'LastThisOpponentLost'] = xx['LastThisOpponentLost']\n",
    "\n",
    "        # stats by year/season\n",
    "        for year, groupByYear in all.groupby('Year'):\n",
    "            # print(year)\n",
    "            # keep index as new a column, will be restored and assigned back to X later\n",
    "            idx = groupByYear.index\n",
    "\n",
    "            # make match day an index because rolling need an index date\n",
    "            xx = groupByYear.set_index('Date')\n",
    "            xx['idx'] = idx\n",
    "\n",
    "            # shift to exclude self\n",
    "            xx['CornersSoFar'] = np.nancumsum(xx['Corners'].shift())\n",
    "            xx['ShotsSoFar'] = np.nancumsum(xx['Shots'].shift())\n",
    "            xx['ShotsOnTargetSoFar'] = np.nancumsum(xx['ShotsOnTarget'].shift())\n",
    "            xx['GoalsSoFar'] = np.nancumsum(xx['Goals'].shift())\n",
    "            xx['ConcededSoFar'] = np.nancumsum(xx['Conceded'].shift())\n",
    "\n",
    "            xx['HomeWonNum'] = np.where(xx['HomeMatch'] & xx['Won'], 1, 0)\n",
    "            xx['HomeWonSoFar'] = np.nancumsum(xx['HomeWonNum'].shift())\n",
    "            xx['AwayWonNum'] = np.where((xx['HomeMatch'] == False) & xx['Won'], 1, 0)\n",
    "            xx['AwayWonSoFar'] = np.nancumsum(xx['AwayWonNum'].shift())\n",
    "\n",
    "            xx['PointsSoFar'] = np.nancumsum(xx['Points'].shift())\n",
    "            xx['AdjustedPointsSoFar'] = np.nancumsum(xx['AdjustedPoints'].shift())\n",
    "\n",
    "            # restore index\n",
    "            xx = xx.set_index('idx')\n",
    "\n",
    "            # assign back to the big dataframe\n",
    "            # all.loc[xx.index, 'CornersSoFar'] = xx['CornersSoFar']\n",
    "            # all.loc[xx.index, 'ShotsSoFar'] = xx['ShotsSoFar']\n",
    "            # all.loc[xx.index, 'ShotsOnTargetSoFar'] = xx['ShotsOnTargetSoFar']\n",
    "            # all.loc[xx.index, 'GoalsSoFar'] = xx['GoalsSoFar']\n",
    "            # all.loc[xx.index, 'ConcededSoSoFar'] = xx['ConcededSoSoFar']\n",
    "#             all.loc[xx.index, 'HomeWonSoFar'] = xx['HomeWonSoFar']\n",
    "#             all.loc[xx.index, 'AwayWonSoFar'] = xx['AwayWonSoFar']\n",
    "            all.loc[xx.index, 'PointsSoFar'] = xx['PointsSoFar']\n",
    "            all.loc[xx.index, 'AdjustedPointsSoFar'] = xx['AdjustedPointsSoFar']\n",
    "\n",
    "        # find recent forms\n",
    "        idx = all.index\n",
    "        xx = all.set_index('Date')\n",
    "        xx['idx'] = idx\n",
    "        xx['Last5Won'] = xx['Won'].rolling(6).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "        xx['Last5Draw'] = xx['Draw'].rolling(6).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "        # xx['Last5Lost'] = xx['Lost'].rolling(6).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "        xx['Last3Won'] = xx['Won'].rolling(4).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "        xx['Last3Draw'] = xx['Draw'].rolling(4).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "        xx['LastWon'] = xx['Won'].rolling(2).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "        xx['LastDraw'] = xx['Draw'].rolling(2).apply(lambda x: np.nansum(x.shift()), raw=False)\n",
    "\n",
    "        # restore index\n",
    "        xx = xx.set_index('idx')\n",
    "        # assign back to the big dataframe\n",
    "        all.loc[xx.index, 'Last5Won'] = xx['Last5Won']\n",
    "        all.loc[xx.index, 'Last5Draw'] = xx['Last5Draw']\n",
    "        all.loc[xx.index, 'Last3Won'] = xx['Last3Won']\n",
    "        all.loc[xx.index, 'Last3Draw'] = xx['Last3Draw']\n",
    "        all.loc[xx.index, 'LastWon'] = xx['LastWon']\n",
    "        all.loc[xx.index, 'LastDraw'] = xx['LastDraw']\n",
    "        # X.loc[xx.index, 'Last5Lost'] = xx['Last5Lost']\n",
    "\n",
    "        # replace nan with 0\n",
    "        # TODO: better way to handle nan\n",
    "        # all.loc[np.isnan(all['FTR']), 'FTR'] = ''\n",
    "        all.loc[np.isnan(all['Last5AgainstThisOpponentWon']), 'Last5AgainstThisOpponentWon'] = 0\n",
    "        all.loc[np.isnan(all['Last5AgainstThisOpponentDraw']), 'Last5AgainstThisOpponentDraw'] = 0\n",
    "        # X.loc[np.isnan(X['Last5AgainstThisOpponentLost']), 'Last5AgainstThisOpponentLost'] = 0\n",
    "        all.loc[np.isnan(all['Last3AgainstThisOpponentWon']), 'Last3AgainstThisOpponentWon'] = 0\n",
    "        all.loc[np.isnan(all['Last3AgainstThisOpponentDraw']), 'Last3AgainstThisOpponentDraw'] = 0\n",
    "        all.loc[np.isnan(all['LastAgainstThisOpponentWon']), 'LastAgainstThisOpponentWon'] = 0\n",
    "        all.loc[np.isnan(all['LastAgainstThisOpponentDraw']), 'LastAgainstThisOpponentDraw'] = 0\n",
    "        # X.loc[np.isnan(X['LastThisOpponentLost']), 'LastThisOpponentLost'] = 0\n",
    "        all.loc[np.isnan(all['Last5Won']), 'Last5Won'] = 0\n",
    "        all.loc[np.isnan(all['Last5Draw']), 'Last5Draw'] = 0\n",
    "        # X.loc[np.isnan(X['Last5Lost']), 'Last5Lost'] = 0\n",
    "        all.loc[np.isnan(all['Last3Won']), 'Last3Won'] = 0\n",
    "        all.loc[np.isnan(all['Last3Draw']), 'Last3Draw'] = 0\n",
    "        all.loc[np.isnan(all['LastWon']), 'LastWon'] = 0\n",
    "        all.loc[np.isnan(all['LastDraw']), 'LastDraw'] = 0\n",
    "        all.loc[np.isnan(all['B365Diff']), 'B365Diff'] = 0\n",
    "\n",
    "        # restrict training data (too old data may not be irrelevance)\n",
    "        X = all\n",
    "        Y = X[['Result']]\n",
    "        # del X['Result']\n",
    "        # X = all.loc[(all['Year'] >= train_year) & (all['Year'] < predict_year)]\n",
    "        # Y = all[['Result']]\n",
    "\n",
    "        # split data into train - test sets\n",
    "        # x_train = X[(X['Year'] < predict_year)]\n",
    "        # y_train = Y[(X['Year'] < predict_year)]\n",
    "        # x_test = X[(X['Year'] >= predict_year)]\n",
    "        # y_test = Y[(X['Year'] >= predict_year)]\n",
    "        # X['Predict'] = ''\n",
    "        close_leaks(X)\n",
    "        ret[team] = [X, Y]\n",
    "    return ret\n",
    "\n",
    "\n",
    "# call this after you've split data\n",
    "def close_leaks(X):\n",
    "    # remove duplicate features\n",
    "#     del X['LastWon']\n",
    "#     del X['LastDraw']\n",
    "\n",
    "    # prevent future leaks\n",
    "    # result = pd.DataFrame(X['Result'])\n",
    "    del X['Result']\n",
    "    del X['Lost']\n",
    "    del X['Draw']\n",
    "    del X['Won']\n",
    "    del X['FTR']\n",
    "    del X['Date']\n",
    "    del X['Opponent']\n",
    "    del X['Team']\n",
    "    del X['B365Max']\n",
    "    del X['B365Min']\n",
    "    del X['Corners']\n",
    "    del X['Shots']\n",
    "    del X['ShotsOnTarget']\n",
    "    del X['Points']\n",
    "    del X['AdjustedPoints']\n",
    "    del X['Goals']\n",
    "    del X['Conceded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = 'english'\n",
    "validate_year = 2016\n",
    "test_year = 2017\n",
    "train_year = 2005\n",
    "df = load_league_csv(league)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arsenal' 'Bournemouth' 'Brighton' 'Burnley' 'Chelsea' 'Crystal Palace'\n",
      " 'Everton' 'Huddersfield' 'Hull' 'Leicester' 'Liverpool' 'Man City'\n",
      " 'Man United' 'Middlesbrough' 'Newcastle' 'Southampton' 'Stoke'\n",
      " 'Sunderland' 'Swansea' 'Tottenham' 'Watford' 'West Brom' 'West Ham']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "teams = df.loc[(df['Year'] == validate_year) | (df['Year'] == test_year), 'HomeTeam']\n",
    "teams = teams.unique()\n",
    "teams.sort()\n",
    "print(teams)\n",
    "print(len(teams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = make_features(df, teams)\n",
    "classes = ['Draw', 'Lose', 'Win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Year                            494\n",
      "HomeMatch                       494\n",
      "B365Say                         494\n",
      "B365Diff                        494\n",
      "Last5AgainstThisOpponentWon     494\n",
      "Last5AgainstThisOpponentDraw    494\n",
      "Last3AgainstThisOpponentWon     494\n",
      "Last3AgainstThisOpponentDraw    494\n",
      "LastAgainstThisOpponentWon      494\n",
      "LastAgainstThisOpponentDraw     494\n",
      "PointsSoFar                     494\n",
      "AdjustedPointsSoFar             494\n",
      "Last5Won                        494\n",
      "Last5Draw                       494\n",
      "Last3Won                        494\n",
      "Last3Draw                       494\n",
      "LastWon                         494\n",
      "LastDraw                        494\n",
      "dtype: int64\n",
      "Y\n",
      "Result    494\n",
      "dtype: int64\n",
      "23 teams\n"
     ]
    }
   ],
   "source": [
    "print('X')\n",
    "print(teams[next(iter(teams))][0].count()) # X\n",
    "print('Y')\n",
    "print(teams[next(iter(teams))][1].count()) # Y\n",
    "print(len(teams), 'teams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Arsenal validation accuracy are: 47.368421052631575\n",
      "LogisticRegression: Arsenal test accuracy are: 47.368421052631575\n",
      "LogisticRegression: Bournemouth validation accuracy are: 47.368421052631575\n",
      "LogisticRegression: Bournemouth test accuracy are: 55.26315789473685\n",
      "skip Brighton\n",
      "LogisticRegression: Burnley validation accuracy are: 44.73684210526316\n",
      "LogisticRegression: Burnley test accuracy are: 28.947368421052634\n",
      "LogisticRegression: Chelsea validation accuracy are: 50.0\n",
      "LogisticRegression: Chelsea test accuracy are: 39.473684210526315\n",
      "LogisticRegression: Crystal Palace validation accuracy are: 39.473684210526315\n",
      "LogisticRegression: Crystal Palace test accuracy are: 44.73684210526316\n",
      "LogisticRegression: Everton validation accuracy are: 47.368421052631575\n",
      "LogisticRegression: Everton test accuracy are: 50.0\n",
      "skip Huddersfield\n",
      "skip Hull\n",
      "LogisticRegression: Leicester validation accuracy are: 50.0\n",
      "LogisticRegression: Leicester test accuracy are: 39.473684210526315\n",
      "LogisticRegression: Liverpool validation accuracy are: 28.947368421052634\n",
      "LogisticRegression: Liverpool test accuracy are: 36.84210526315789\n",
      "LogisticRegression: Man City validation accuracy are: 50.0\n",
      "LogisticRegression: Man City test accuracy are: 68.42105263157895\n",
      "LogisticRegression: Man United validation accuracy are: 44.73684210526316\n",
      "LogisticRegression: Man United test accuracy are: 39.473684210526315\n",
      "skip Middlesbrough\n",
      "skip Newcastle\n",
      "LogisticRegression: Southampton validation accuracy are: 36.84210526315789\n",
      "LogisticRegression: Southampton test accuracy are: 42.10526315789473\n",
      "LogisticRegression: Stoke validation accuracy are: 34.21052631578947\n",
      "LogisticRegression: Stoke test accuracy are: 55.26315789473685\n",
      "skip Sunderland\n",
      "LogisticRegression: Swansea validation accuracy are: 31.57894736842105\n",
      "LogisticRegression: Swansea test accuracy are: 42.10526315789473\n",
      "LogisticRegression: Tottenham validation accuracy are: 47.368421052631575\n",
      "LogisticRegression: Tottenham test accuracy are: 39.473684210526315\n",
      "LogisticRegression: Watford validation accuracy are: 60.526315789473685\n",
      "LogisticRegression: Watford test accuracy are: 44.73684210526316\n",
      "LogisticRegression: West Brom validation accuracy are: 42.10526315789473\n",
      "LogisticRegression: West Brom test accuracy are: 39.473684210526315\n",
      "LogisticRegression: West Ham validation accuracy are: 21.052631578947366\n",
      "LogisticRegression: West Ham test accuracy are: 28.947368421052634\n"
     ]
    }
   ],
   "source": [
    "total = None\n",
    "for team in teams:\n",
    "# for team in ['Arsenal']:\n",
    "    X = teams[team][0]\n",
    "    Y = teams[team][1]\n",
    "    # split data into train - validate - test sets\n",
    "    x_train = X[(X['Year'] >= train_year) & (X['Year'] < validate_year)]\n",
    "    y_train = Y[(X['Year'] >= train_year) & (X['Year'] < validate_year)]\n",
    "    x_validate = X[(X['Year'] >= validate_year) & (X['Year'] < test_year)]\n",
    "    y_validate = Y[(X['Year'] >= validate_year) & (X['Year'] < test_year)]\n",
    "    x_test = X[(X['Year'] >= test_year)]\n",
    "    y_test = Y[(X['Year'] >= test_year)]\n",
    "    if len(x_train) <= 0 or len(x_test) <= 0 or len(x_validate) <= 0:\n",
    "        print(f'skip {team}')\n",
    "        continue\n",
    "    \n",
    "    validate_accuracies = {}\n",
    "    test_accuracies = {}\n",
    "    \n",
    "    clf_entropy = DecisionTreeClassifier(\n",
    "#             criterion=\"gini\",\n",
    "            criterion=\"entropy\",\n",
    "            random_state=100,\n",
    "            # max_depth=3,\n",
    "            min_samples_leaf=5\n",
    "            # min_samples_leaf=3\n",
    "        )\n",
    "    clf_entropy.fit(x_train, y_train['Result'])\n",
    "    y_validate_pred = clf_entropy.predict(x_validate)\n",
    "    validate_accuracies['LogisticRegression'] = accuracy_score(y_validate, y_validate_pred) * 100\n",
    "    y_test_pred = clf_entropy.predict(x_test)\n",
    "    test_accuracies['LogisticRegression'] = accuracy_score(y_test, y_test_pred) * 100\n",
    "    d = pd.DataFrame(\n",
    "        data={\n",
    "            'Year': x_validate['Year'].append(x_test['Year']),\n",
    "            'Team': team,\n",
    "            'Predict': np.append(y_validate_pred, y_test_pred),\n",
    "            'Actual': y_validate['Result'].append(y_test['Result'])\n",
    "        },\n",
    "        index=np.append(y_validate.index, y_test.index)\n",
    "    )\n",
    "    if total is None:\n",
    "        total = d\n",
    "    else:\n",
    "        total = total.append(d)\n",
    "    for (k, v) in validate_accuracies.items():\n",
    "        print(f\"{k}: {team} validation accuracy are: {v}\")\n",
    "#         cm = confusion_matrix(y_validate, y_validate_pred, labels=classes)\n",
    "#         metrics.plot_confusion_matrix(cm, classes, title=team)\n",
    "        print(f\"{k}: {team} test accuracy are: {test_accuracies[k]}\")\n",
    "#         cm = confusion_matrix(y_test, y_test_pred, labels=classes)\n",
    "#         metrics.plot_confusion_matrix(cm, classes, title=team)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy is  43.11145510835913\n"
     ]
    }
   ],
   "source": [
    "# for key, groupByPredictor in total.groupby('predictor'):\n",
    "#     print(f\"{key} overall accuracy is \", accuracy_score(groupByPredictor['actual'], groupByPredictor['pred'])*100)\n",
    "print(f\"Overall accuracy is \", accuracy_score(total['Actual'], total['Predict'])*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
